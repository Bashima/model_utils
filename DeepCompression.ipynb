{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import h5py\n",
    "from keras.models import model_from_json\n",
    "from matplotlib import pyplot as plt \n",
    "from skimage import io\n",
    "from keras import backend as K\n",
    "from scipy.cluster.vq import vq, kmeans, whiten, kmeans2\n",
    "from keras.models import load_model\n",
    "from tempfile import TemporaryFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from json and h5 (has both the model and the weight)\n",
    "def loadModelJsonH5(model_name):\n",
    "#     load the model architecture from the json file\n",
    "    json_file = open(model_name + '.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    \n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    \n",
    "#     load the model parameters (weights) from the h5 file\n",
    "    loaded_model.load_weights(model_name + \".h5\")\n",
    "    \n",
    "#     print the summary of the model \n",
    "    loaded_model.summary()\n",
    "    \n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from json (has the model only, no weight)\n",
    "def loadModelJson(model_name):\n",
    "#     load the model architecture from the json file\n",
    "    json_file = open(model_name + '.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    \n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    \n",
    "#     print the summary of the model \n",
    "#     loaded_model.summary()\n",
    "    \n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model from h5 (both model and weight)\n",
    "def loadModelH5(model_name):\n",
    "    filename = model_name + \".h5\";\n",
    "    print(filename)\n",
    "    loaded_model = load_model(filename);\n",
    "#     loaded_model.summary()\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quantize the weights\n",
    "#inputs are weights of a layer, number of cluster (how many numbers we can save, 8 usually works well) and 0/1 (1 if we want to vizualize)\n",
    "\n",
    "def quantize_weights(wts, numClusters, viz_codeX):\n",
    "    original_data=np.copy(wts)\n",
    "    nz_idx=np.nonzero(original_data)\n",
    "    nz_data=original_data[nz_idx]\n",
    "    F=nz_data.flatten()\n",
    "    F=F.reshape(-1,1)\n",
    "    InitC=np.linspace(F.min(),F.max(),num=numClusters) #linear initialization is done. According to the paper this gives better result\n",
    "    codebook, codeX=kmeans2(F, InitC.reshape(-1,1), minit='matrix')\n",
    "    \n",
    "    if viz_codeX==1:\n",
    "        print(codebook)\n",
    "        print(len(codeX))\n",
    "        # edges_hist=[x for x in range(numClusters+1)]\n",
    "        # frq, edges = np.histogram(codeX,edges_hist)\n",
    "        # print(frq,edges)\n",
    "        # fig, ax = plt.subplots()\n",
    "        # ax.bar(edges[:-1], frq, width=np.diff(edges), ec=\"k\", align=\"edge\")\n",
    "        # plt.title(\"cluster value histogram\")\n",
    "        # plt.show()\n",
    "    return codebook, codeX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disrcetize_wts(weight):\n",
    "    min_wt = weight.min() \n",
    "    max_wt = weight.max()\n",
    "    #find number of integer bits to represent this range\n",
    "    int_bits = int(np.ceil(np.log2(max(abs(min_wt),abs(max_wt))))) \n",
    "    frac_bits = 7-int_bits #remaining bits are fractional bits (1-bit for sign)\n",
    "    #floating point weights are scaled and rounded to [-128,127], which are used in \n",
    "    #the fixed-point operations on the actual hardware (i.e., microcontroller)\n",
    "    quant_weight = np.round(weight*(2**frac_bits))\n",
    "    #To quantify the impact of quantized weights, scale them back to\n",
    "    # original range to run inference using quantized weights\n",
    "#     weight = quant_weight/(2**frac_bits)\n",
    "    return quant_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the weight from the codeX and codeVal\n",
    "def create_codeVal(codeX, codebook, wts_shape):\n",
    "    code_val=np.zeros(codeX.shape)\n",
    "    for idx,val in enumerate(codeX):\n",
    "        code_val[idx]=codebook[val]\n",
    "    new_wts=code_val.reshape(wts_shape)\n",
    "    return new_wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models/tr.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bashima/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n",
      "/home/bashima/anaconda3/lib/python3.6/site-packages/scipy/cluster/vq.py:525: UserWarning: One of the clusters is empty. Re-run kmeans with a different initialization.\n",
      "  warnings.warn(\"One of the clusters is empty. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.convolutional.Conv1D object at 0x7fccbee819b0>\n",
      "(2,)\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fccbee81c50>\n",
      "(4, 16)\n",
      "<keras.layers.core.Activation object at 0x7fccbee81c18>\n",
      "(0,)\n",
      "<keras.layers.pooling.MaxPooling1D object at 0x7fccbee90780>\n",
      "(0,)\n",
      "<keras.layers.convolutional.Conv1D object at 0x7fccbef1bfd0>\n",
      "(2,)\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fccbedfdcc0>\n",
      "(4, 16)\n",
      "<keras.layers.core.Activation object at 0x7fccbede3908>\n",
      "(0,)\n",
      "<keras.layers.pooling.MaxPooling1D object at 0x7fccbed2b470>\n",
      "(0,)\n",
      "<keras.layers.convolutional.Conv1D object at 0x7fccbeda7e10>\n",
      "(2,)\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fccbec063c8>\n",
      "(4, 32)\n",
      "<keras.layers.core.Activation object at 0x7fccbed2b400>\n",
      "(0,)\n",
      "<keras.layers.pooling.MaxPooling1D object at 0x7fccbebdb128>\n",
      "(0,)\n",
      "<keras.layers.convolutional.Conv1D object at 0x7fccbec06978>\n",
      "(2,)\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fccbeae4940>\n",
      "(4, 64)\n",
      "<keras.layers.core.Activation object at 0x7fccbeac0e80>\n",
      "(0,)\n",
      "<keras.layers.pooling.MaxPooling1D object at 0x7fccbeabd2b0>\n",
      "(0,)\n",
      "<keras.layers.core.Lambda object at 0x7fccbeae4dd8>\n",
      "(0,)\n",
      "<keras.layers.core.Dense object at 0x7fccbea5ab38>\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "#Sample code for loading a model and quantize_weights. Then we quantize it so what we store are interger values of weights\n",
    "# def sample_quantize_weights\n",
    "\n",
    "# model = loadModelJsonH5(\"Models/model3\")\n",
    "def sample_quantize(modelname):\n",
    "    codebooks = []\n",
    "    codeXs = []\n",
    "    cluster_number = 8\n",
    "    model = loadModelH5(modelname)\n",
    "    for layer in model.layers:\n",
    "        print(layer)\n",
    "        existing_weight = layer.get_weights()\n",
    "        existing_weight_np = np.asarray(existing_weight)\n",
    "        print(existing_weight_np.shape)\n",
    "    #     If convolution layer then there is both weight and bias index 0 is weight and index 1 is bias\n",
    "        if existing_weight_np.shape == (2,):\n",
    "            for i in range (0,2):\n",
    "                codebook, codeX = quantize_weights(existing_weight_np[i], cluster_number, 0)\n",
    "                codebooks.append(codebook)\n",
    "                codeXs.append(codeX)\n",
    "        elif existing_weight_np.shape != (0,) :\n",
    "            codebook, codeX = quantize_weights(existing_weight_np, cluster_number, 0)\n",
    "            codebooks.append(codebook)\n",
    "            codeXs.append(codeX)\n",
    "    return codebooks, codeXs\n",
    "#         by saving the codebook, codeX and the shape of the weight we can save space. \n",
    "\n",
    "\n",
    "# this calls the sample function\n",
    "codebook, codeX = sample_quantize(\"tr\")\n",
    "#Now we will save them \n",
    "np.save(\"codebook_file.npy\", codebook)\n",
    "\n",
    "codeX_file = TemporaryFile()\n",
    "np.save(\"codeX_file.npy\", codeX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models/tr.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bashima/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n",
      "/home/bashima/anaconda3/lib/python3.6/site-packages/scipy/cluster/vq.py:525: UserWarning: One of the clusters is empty. Re-run kmeans with a different initialization.\n",
      "  warnings.warn(\"One of the clusters is empty. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.convolutional.Conv1D object at 0x7fccbc00f518>\n",
      "(2,)\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fccbc00f9b0>\n",
      "(4, 16)\n",
      "<keras.layers.core.Activation object at 0x7fccbc00fac8>\n",
      "(0,)\n",
      "<keras.layers.pooling.MaxPooling1D object at 0x7fccbc01eeb8>\n",
      "(0,)\n",
      "<keras.layers.convolutional.Conv1D object at 0x7fccbc03be48>\n",
      "(2,)\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fccbbd12940>\n",
      "(4, 16)\n",
      "<keras.layers.core.Activation object at 0x7fccbc00f7b8>\n",
      "(0,)\n",
      "<keras.layers.pooling.MaxPooling1D object at 0x7fccbbc9aef0>\n",
      "(0,)\n",
      "<keras.layers.convolutional.Conv1D object at 0x7fccbbcfb8d0>\n",
      "(2,)\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fccbbbedc50>\n",
      "(4, 32)\n",
      "<keras.layers.core.Activation object at 0x7fccbbbd5860>\n",
      "(0,)\n",
      "<keras.layers.pooling.MaxPooling1D object at 0x7fccbbb76550>\n",
      "(0,)\n",
      "<keras.layers.convolutional.Conv1D object at 0x7fccbbb1b390>\n",
      "(2,)\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fccbba7a588>\n",
      "(4, 64)\n",
      "<keras.layers.core.Activation object at 0x7fccbbb4af28>\n",
      "(0,)\n",
      "<keras.layers.pooling.MaxPooling1D object at 0x7fccbb9ce278>\n",
      "(0,)\n",
      "<keras.layers.core.Lambda object at 0x7fccbba7afd0>\n",
      "(0,)\n",
      "<keras.layers.core.Dense object at 0x7fccbb9f46a0>\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "#Sample code for loading a model and quantize_weights. Then we quantize it so what we store are interger values of weights\n",
    "# def sample_quantize_weights\n",
    "\n",
    "# model = loadModelJsonH5(\"Models/model3\")\n",
    "def sample_quantize_discretize(modelname):\n",
    "    codebooks = []\n",
    "    codeXs = []\n",
    "    cluster_number = 8\n",
    "    model = loadModelH5(modelname)\n",
    "    for layer in model.layers:\n",
    "        print(layer)\n",
    "        existing_weight = layer.get_weights()\n",
    "        existing_weight_np = np.asarray(existing_weight)\n",
    "        print(existing_weight_np.shape)\n",
    "    #     If convolution layer then there is both weight and bias index 0 is weight and index 1 is bias\n",
    "        if existing_weight_np.shape == (2,):\n",
    "            for i in range (0,2):\n",
    "                codebook, codeX = quantize_weights(existing_weight_np[i], cluster_number, 0)\n",
    "                codebook_discrete = disrcetize_wts(codebook)\n",
    "                codebooks.append(codebook_discrete)\n",
    "                codeXs.append(codeX)\n",
    "        elif existing_weight_np.shape != (0,) :\n",
    "            codebook, codeX = quantize_weights(existing_weight_np, cluster_number, 0)\n",
    "            codebook_discrete = disrcetize_wts(codebook)\n",
    "            codebooks.append(codebook_discrete)\n",
    "            codeXs.append(codeX)\n",
    "    return codebooks, codeXs\n",
    "#         by saving the codebook, codeX and the shape of the weight we can save space. \n",
    "\n",
    "\n",
    "# this calls the sample function\n",
    "codebook, codeX = sample_quantize_discretize(\"tr\")\n",
    "#Now we will save them \n",
    "np.save(\"codebook_file_dis.npy\", codebook)\n",
    "\n",
    "codeX_file = TemporaryFile()\n",
    "np.save(\"codeX_file_dis.npy\", codeX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.convolutional.Conv1D object at 0x7fccbb786780>\n",
      "[array([[[   3.,    3.,  -42., ..., -123.,   72.,    3.]],\n",
      "\n",
      "       [[   3.,    3.,  -18., ...,  -42.,    3.,   44.]],\n",
      "\n",
      "       [[ -18.,  -18.,  -18., ...,   23.,    3.,    3.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ -42.,  -18.,   23., ...,   23.,  -18.,    3.]],\n",
      "\n",
      "       [[  23.,    3.,  -42., ...,    3.,  -18.,    3.]],\n",
      "\n",
      "       [[  23.,   23.,   23., ...,  -18.,    3.,   23.]]], dtype=float32)\n",
      " array([ 39., -39.,  16., -39.,  16., -39.,  16.,  16., -90., -39.,  61.,\n",
      "       -23., -23.,  87.,  87.,  16.], dtype=float32)]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fccbb786a20>\n",
      "[[62. 67. 62. 62. 62. 62. 62. 62. 62. 67. 67. 67. 67. 67. 62. 67.]\n",
      " [16.  4.  4.  4. 16. -1. -1. -1. -1.  4. -1. -1. -1. -1.  4. -1.]\n",
      " [ 4. -1.  4. -1.  4. -1. -1.  4. -1. -1.  4. -1. -1.  4.  4. -1.]\n",
      " [ 4. 26. 16. 16. 16. 16. 16. 26. 26. 16. 16. 26. 44. 26. 26. 16.]]\n",
      "<keras.layers.core.Activation object at 0x7fccbb7869e8>\n",
      "[]\n",
      "<keras.layers.pooling.MaxPooling1D object at 0x7fccbb78a400>\n",
      "[]\n",
      "<keras.layers.convolutional.Conv1D object at 0x7fccbc75fa58>\n",
      "[array([[[-19., -43., -19.,   5.,   5.,  27.,  70.,   5., -19., -94.,\n",
      "          27.,   5.,  47., -19.,  27.,  27.],\n",
      "        [-19., -43.,   5., -43., -43., -43.,  47.,  27.,   5.,   5.,\n",
      "           5.,  47., -94., -19.,  70.,  70.],\n",
      "        [ 47., -19.,   5.,  27.,  27.,  47.,  27., -43.,   5.,   5.,\n",
      "          27.,  47.,  27., -19., -61.,  70.],\n",
      "        [ 27.,  27.,  70., -43., -19., -61., -43., -61., -43., -19.,\n",
      "         -19., -43., -19., -19., -19., -43.],\n",
      "        [-43.,  47.,  47.,  27., -19.,   5., -43., -61.,   5.,   5.,\n",
      "           5.,   5., -19.,  27.,  70.,  47.],\n",
      "        [ 27.,  47.,   5., -43.,  47., -61., -19., -43.,   5., -61.,\n",
      "         -19., -61.,   5., -61., -61.,  47.],\n",
      "        [-43.,   5.,   5.,  47., -43.,   5., -19., -43.,  27.,  27.,\n",
      "          47.,  27., -19., -43.,  27., -43.],\n",
      "        [ 70.,  47.,  27.,   5.,   5., -19., -43., -19., -43., -19.,\n",
      "           5., -43.,  27., -61., -43., -94.],\n",
      "        [-43., -43.,   5.,  27., -43.,   5., -43.,   5., -43., -19.,\n",
      "           5.,   5.,   5.,   5., -19.,   5.],\n",
      "        [ 27.,  27.,  47.,  27.,  27.,   5.,   5., -19.,   5.,  27.,\n",
      "         -19., -43.,  27.,   5., -19.,   5.],\n",
      "        [  5., -43.,   5.,  27., -43., -61., -43.,  47., -94., -19.,\n",
      "          70., -61., -43., -19.,  70.,   5.],\n",
      "        [ 70.,  47., -61., -43.,  70., -19., -43.,   5., -19.,   5.,\n",
      "           5., -19.,  70., -19., -43., -19.],\n",
      "        [-43., -19., -19., -19.,  27.,  70.,   5.,  27., -94.,  27.,\n",
      "         -19., -94.,  47.,  27.,  27., -43.],\n",
      "        [ 47.,   5.,  70.,  27.,  27., -61.,  27., -19., -19., -61.,\n",
      "           5., -19., -19., -19.,   5., -19.],\n",
      "        [  5.,  27.,  47., -19.,   5.,   5.,   5., -19.,  47., -19.,\n",
      "          70.,  27., -43.,  47., -61.,  47.],\n",
      "        [-61.,  70.,  27., -19.,  27.,   5., -61., -19., -61., -19.,\n",
      "          70.,  47.,  47.,   5., -43., -43.]],\n",
      "\n",
      "       [[ 27., -43.,  27.,   5.,   5.,   5.,   5., -19.,   5., -43.,\n",
      "           5., -43., -19., -19.,  27.,   5.],\n",
      "        [ 70., -43.,  47., -43., -61., -19.,  47., -19.,   5.,  27.,\n",
      "          27., -61., -43., -43.,   5., -19.],\n",
      "        [-19.,   5., -19.,  47.,   5.,   5.,  27., -43.,  27.,  27.,\n",
      "         -43.,  47.,  27., -43.,  47.,   5.],\n",
      "        [ 27., -19.,  47.,  47.,  47., -19.,  27., -43.,  27., -43.,\n",
      "          47.,  27., -43., -19., -43., -43.],\n",
      "        [-43., -19.,  70.,   5., -19.,   5., -43., -43.,  47., -43.,\n",
      "          47.,  27., -19., -61.,   5.,  70.],\n",
      "        [-61.,   5.,  47.,  47., -19.,  47.,   5., -43., -61., -61.,\n",
      "           5.,  47., -19.,   5., -43.,   5.],\n",
      "        [ 27.,  27., -19., -61., -43., -43., -43.,  47.,   5.,   5.,\n",
      "         -19.,  27., -43., -61.,  47., -19.],\n",
      "        [ 47., -19., -43., -19.,   5.,  47., -43., -43., -43., -43.,\n",
      "         -19., -43., -43., -61., -43., -19.],\n",
      "        [  5., -19., -19.,   5., -61., -19.,  27., -61.,   5.,  47.,\n",
      "          27.,  47.,  27.,  27.,   5., -61.],\n",
      "        [-19., -19.,  47.,   5.,  27.,   5.,   5., -94., -43., -43.,\n",
      "         -61., -43.,  27.,   5., -43.,  47.],\n",
      "        [-61.,  47.,  27.,   5., -19., -43.,  27.,  47., -19.,  47.,\n",
      "          27., -43., -61.,  27.,  27., -19.],\n",
      "        [ 27.,  27., -61.,  47., -61.,   5., -19., -43.,  47.,   5.,\n",
      "           5.,  47., -19., -43.,  27., -94.],\n",
      "        [-19.,  27.,  47., -43., -19., -19., -19., -43.,  27.,   5.,\n",
      "         -94., -43.,  27., -19., -19., -19.],\n",
      "        [-43., -19.,  27., -43.,  70.,  47.,  70., -43., -43., -19.,\n",
      "          70., -43., -19.,  70.,  47.,  27.],\n",
      "        [-61.,  27.,  47.,  47., -43.,  27.,  70.,  47.,  27., -61.,\n",
      "          70., -61., -61.,  27., -43., -19.],\n",
      "        [-61.,  47., -43., -19.,   5., -19., -19.,  27.,   5.,  27.,\n",
      "          70.,   5., -19.,  27.,  27., -43.]],\n",
      "\n",
      "       [[-61., -19., -19.,  70.,   5.,   5., -19.,  27.,  27.,   5.,\n",
      "          47.,   5., -19.,  27., -61.,  27.],\n",
      "        [  5.,   5.,  70.,  70., -19., -43.,   5.,   5.,  27.,   5.,\n",
      "         -19., -19., -94., -19., -19., -43.],\n",
      "        [-61., -61.,   5., -43., -61.,  47., -19.,   5., -43., -43.,\n",
      "          27., -43.,  27., -43., -43., -43.],\n",
      "        [ 47.,   5.,  27.,   5.,  27., -61.,  27.,   5.,  47.,  27.,\n",
      "          27., -61., -19.,  27.,  47., -94.],\n",
      "        [  5.,   5.,  47., -43.,  47.,  27.,  27., -19.,   5.,  27.,\n",
      "          27.,   5.,  47., -19., -43., -19.],\n",
      "        [  5.,   5.,   5., -43., -19., -19., -19., -43., -19., -61.,\n",
      "          27.,  47.,  47.,  47., -61., -43.],\n",
      "        [ 27.,  27., -43., -43., -19.,   5., -43.,  47.,  47., -19.,\n",
      "           5.,  27.,  47., -43.,  47., -19.],\n",
      "        [ 27.,  70., -19.,  27., -19.,  27., -19.,  47.,   5.,   5.,\n",
      "         -43.,  27., -19.,  47.,   5., -19.],\n",
      "        [ 47.,  47., -19.,  27., -19.,  70.,   5.,  27., -94., -19.,\n",
      "           5.,  70.,  70.,  47.,  27., -43.],\n",
      "        [  5.,  27.,  27.,  47.,  27., -43.,  27., -43., -43.,   5.,\n",
      "         -43.,  70.,   5., -43.,  70.,  27.],\n",
      "        [-43.,  47.,   5.,  47., -43., -43.,   5.,  47., -61.,  47.,\n",
      "           5.,   5.,  47.,  27., -19.,  70.],\n",
      "        [ 70.,   5., -19.,   5.,  47.,  27.,  27.,  70., -19.,  27.,\n",
      "           5., -61., -43.,   5., -19., -43.],\n",
      "        [-19.,   5.,  27.,  47., -61.,  70., -43.,   5., -19., -61.,\n",
      "           5., -94.,   5., -19.,  27.,  27.],\n",
      "        [ 27.,   5., -61.,   5.,  27.,   5.,  47., -61.,   5.,   5.,\n",
      "         -19., -19.,  27., -43.,   5.,   5.],\n",
      "        [ 47.,  27., -19., -19.,  27., -43., -43., -61.,  47., -43.,\n",
      "           5.,   5., -61., -61., -19., -19.],\n",
      "        [-19.,  70., -43., -61.,  27.,  47., -61.,  47., -19., -19.,\n",
      "         -43., -19., -43., -19., -19., -43.]]], dtype=float32)\n",
      " array([ 65.,  53., -12.,  36.,   9.,  53., -12., -21.,  36., -21., -60.,\n",
      "        53.,   9., -12.,   9.,   9.], dtype=float32)]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fccbb6992e8>\n",
      "[[  63.   63.   63.   63.   63.   63.   63.   63.   63.   63.   63.   63.\n",
      "    63.   63.   63.   63.]\n",
      " [  -7.   -7.   -7.   20.   -7.   -7.   -7.   -7.   -7.   20.   -7.   20.\n",
      "    -7.   -7.   -7.   20.]\n",
      " [  20.   90.  114.   20.   -7.   -7.  -53. -108.  -53. -108.   90.  -53.\n",
      "   -53. -108.   -7.  -81.]\n",
      " [  63.   90.   90.   20.   20.   20.   63.  114.   90.   90.   63.   63.\n",
      "    63.  114.   20.   90.]]\n",
      "<keras.layers.core.Activation object at 0x7fccbb6cdf28>\n",
      "[]\n",
      "<keras.layers.pooling.MaxPooling1D object at 0x7fccbb672320>\n",
      "[]\n",
      "<keras.layers.convolutional.Conv1D object at 0x7fccbb614ac8>\n",
      "[array([[[-30., -30., -12., ...,  43.,  25., -12.],\n",
      "        [-12.,  25.,   8., ...,  25., -12., -78.],\n",
      "        [  8.,   8.,  25., ..., -12.,  43., -78.],\n",
      "        ...,\n",
      "        [ 25.,   8., -78., ..., -52., -12., -52.],\n",
      "        [-52.,  43.,   8., ...,  64.,  25., -52.],\n",
      "        [-78.,  43., -30., ...,  25.,  64.,  25.]],\n",
      "\n",
      "       [[  8., -52., -12., ..., -12., -52.,   8.],\n",
      "        [-12.,   8.,   8., ...,  25., -12., -12.],\n",
      "        [-30.,   8.,  43., ...,  43.,  25., -12.],\n",
      "        ...,\n",
      "        [-12.,   8., -78., ...,  25., -12., -52.],\n",
      "        [ 25.,  25.,  25., ...,  43.,   8., -30.],\n",
      "        [ 25., -30.,   8., ...,  25.,  64.,   8.]],\n",
      "\n",
      "       [[ 43.,  25., -12., ...,  64.,  25., -30.],\n",
      "        [-52.,  64.,  25., ...,   8.,  25.,   8.],\n",
      "        [-12.,   8., -12., ...,  64.,  25.,   8.],\n",
      "        ...,\n",
      "        [-30.,  64., -52., ..., -30., -12., -30.],\n",
      "        [ 25., -12.,   8., ..., -30., -52.,  25.],\n",
      "        [  8., -30.,  25., ...,  25., -12., -30.]]], dtype=float32)\n",
      " array([-40.,  -5.,  29., -23.,  -5.,  29., -76.,  46.,  46.,  -5.,  -5.,\n",
      "        14.,  29.,  29.,  14., -40., -40.,  29.,  14.,  14.,  29., -23.,\n",
      "        14., -40., -23.,  14.,  14.,  -5.,  14.,  14., -40.,  29.],\n",
      "      dtype=float32)]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fccbb565ba8>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  62.   62.   62.   62.   62.   62.   62.   62.   62.   62.   62.   62.\n",
      "    62.   62.   62.   62.   62.   62.   62.   62.   62.   62.   62.   62.\n",
      "    62.   62.   62.   62.   62.   62.   62.   62.]\n",
      " [ -10.  -10.  -10.   17.  -10.  -10.  -10.  -10.  -10.   17.  -10.  -10.\n",
      "   -10.  -10.  -10.   17.  -10.  -10.  -10.  -10.  -10.  -10.  -10.  -10.\n",
      "   -10.  -10.  -10.   17.  -10.  -10.  -10.   17.]\n",
      " [ -77.   96.  -10.  -77.  -48.  -48.   62.  -10.  -10.  -10.   33.   33.\n",
      "  -120.   62.  -77.  -48.  -10.   17.  -48.   17.   62.   17.  -48.  -77.\n",
      "   -10.  -10.  -48.   62.   62.   33.  -10.  -10.]\n",
      " [  17.   33.   33.   33.   33.   17.   33.   62.   17.   17.   17.   17.\n",
      "    33.   33.   17.   17.   17.   33.   17.   62.   33.   17.   33.   62.\n",
      "    33.   17.   33.   96.   17.   17.   17.   33.]]\n",
      "<keras.layers.core.Activation object at 0x7fccbb699b00>\n",
      "[]\n",
      "<keras.layers.pooling.MaxPooling1D object at 0x7fccbb4c4e10>\n",
      "[]\n",
      "<keras.layers.convolutional.Conv1D object at 0x7fccbb4e6d68>\n",
      "[array([[[ -49.,   42.,   11., ...,  -19.,   42.,   11.],\n",
      "        [  11.,  -80.,   11., ...,  -49.,  -19.,  -80.],\n",
      "        [  74.,  -19.,   11., ...,   11.,   11.,   74.],\n",
      "        ...,\n",
      "        [  11.,  -19.,   11., ...,   42.,  -19.,  -49.],\n",
      "        [  11.,  -19.,   11., ...,   11.,   42.,  -49.],\n",
      "        [  11.,   74., -116., ...,  -49.,  -49.,  -19.]],\n",
      "\n",
      "       [[  42.,  113.,   11., ...,   42.,  -19.,   74.],\n",
      "        [-116.,  -49.,  -49., ...,  -80.,   11.,  -80.],\n",
      "        [ -19.,   74.,  -19., ...,  -49.,   42.,  113.],\n",
      "        ...,\n",
      "        [  42.,   11.,   42., ...,  -19.,  -80.,  -19.],\n",
      "        [  11.,  -19.,   11., ...,   42.,   74.,  -49.],\n",
      "        [  42.,   11.,  -19., ...,  -80.,  -19.,   42.]],\n",
      "\n",
      "       [[ -49.,   11.,  -19., ...,   42.,   11.,   42.],\n",
      "        [ -49.,   11.,  -19., ...,   11.,   11.,   11.],\n",
      "        [  74.,   74.,   11., ...,  -80.,   11.,  -19.],\n",
      "        ...,\n",
      "        [ -49.,  -19.,  -19., ...,   74.,  -49.,   11.],\n",
      "        [ -19.,   11.,  -19., ...,  -19.,   42.,  -80.],\n",
      "        [ -49.,   42.,  -80., ...,  -19.,  -19.,   11.]]], dtype=float32)\n",
      " array([ 45.,  45.,  -1., -46.,  45.,  45., -46., -22.,  21.,  21., -22.,\n",
      "       -46.,  21.,  21.,  21.,  -1.,  -1.,  -1.,  -1., -22.,  -1.,  -1.,\n",
      "        -1.,  21.,  21., -22.,  21.,  21.,  45., -46.,  -1.,  21.,  -1.,\n",
      "        21.,  -1.,  72.,  72., -70., -22.,  45., -22., -46.,  45.,  -1.,\n",
      "       -46., -22.,  21.,  94.,  72.,  21., -70.,  45., -22.,  21.,  45.,\n",
      "        21.,  -1.,  -1.,  94.,  21.,  -1., -46.,  45., -22.],\n",
      "      dtype=float32)]\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fccbb439908>\n",
      "[[ 85.  98.  85.  98.  85.  85.  98.  98.  98.  98.  98.  98.  98.  85.\n",
      "   98.  98.  98.  98.  98.  98.  98.  85.  98.  98.  85.  85.  98.  98.\n",
      "   98.  98.  98.  98.  85.  98.  85.  98.  98.  98.  98.  98.  85.  98.\n",
      "   85.  98.  85.  98.  98.  98.  98.  98.  98.  98.  98.  98.  98.  85.\n",
      "   85.  98.  98.  98.  98.  98.  98.  98.]\n",
      " [  3.   3.   3.   3.   3.   3.  14.  14.   3.   3.  14.  14.   3.   3.\n",
      "   14.   3.   3.  14.   3.   3.   3.   3.   3.   3.  14.  14.   3.  14.\n",
      "   14.   3.   3.  14.   3.  14.   3.   3.   3.  14.   3.   3.   3.   3.\n",
      "    3.  14.   3.   3.   3.  14.   3.   3.  14.   3.   3.   3.  14.  14.\n",
      "    3.   3.  14.  14.   3.  14.   3.   3.]\n",
      " [ 44.  44.  44.  14. -30.  44. -57. -30. -30. -30. -57. -97. -30.   3.\n",
      "  -57. -30.  85.  14. -30. -30.  14.  14.  44.  85. -30. -30. -30. -30.\n",
      "    3.   3.  14. -30.  85.  14.  14. -57. -30. -57.  14.  44.  44.   3.\n",
      "   44.  44.  44.  44.  44. -97. -30.  14. -97.  85.   3.  44. -57.  14.\n",
      "   44.  14. -30.  14. -30.  44.  14.  44.]\n",
      " [ 14.  14.   3.  14.  14.  14.  14.  14.  14.  14.  14.  14.  14.  14.\n",
      "   14.  14.  14.  14.  14.  14.  14.  14.  14.  14.  14.   3.  14.  14.\n",
      "   14.  14.  14.  14.  14.  14.  14.  14.  14.  14.  14.  14.  14.  14.\n",
      "   14.  14.  14.  14.  14.  14.  14.  14.  14.  14.  14.  14.  14.  14.\n",
      "   14.  14.  14.  14.  14.  14.  14.  14.]]\n",
      "<keras.layers.core.Activation object at 0x7fccbb3ba668>\n",
      "[]\n",
      "<keras.layers.pooling.MaxPooling1D object at 0x7fccbb3baf98>\n",
      "[]\n",
      "<keras.layers.core.Lambda object at 0x7fccbb565e80>\n",
      "[]\n",
      "<keras.layers.core.Dense object at 0x7fccbb3baeb8>\n",
      "[array([[ -18.,  -46.,   36.,  -46.,    9.,  -73.,   36.,    9.,  -46.,\n",
      "          36.],\n",
      "       [  58.,   36.,  -46.,  -46.,   36.,   36.,   58.,  -46.,  -46.,\n",
      "         -73.],\n",
      "       [ -73.,   36.,  -18.,  -18.,    9.,    9.,    9.,  -18.,  -46.,\n",
      "          58.],\n",
      "       [-110.,    9.,   58.,   36.,    9.,   58.,  -46.,  -46.,  -46.,\n",
      "           9.],\n",
      "       [   9.,  -18.,  -46.,  -18.,  -46.,    9.,    9.,    9.,   58.,\n",
      "          58.],\n",
      "       [  36.,   36.,  -46.,  -46.,  -18.,    9.,   58.,  -46.,    9.,\n",
      "         -18.],\n",
      "       [ -73.,  -46.,  -46.,   58.,   36., -110.,    9.,   58.,    9.,\n",
      "           9.],\n",
      "       [  58.,  -18.,  -46.,  -46.,  -73., -110.,  -46.,   58.,   36.,\n",
      "           9.],\n",
      "       [   9.,    9.,  -73.,   58.,  -18.,  -18.,   36.,  -18.,  -46.,\n",
      "          36.],\n",
      "       [ -73.,  -46.,   36.,  -46.,    9.,   58.,  -46.,  -46.,   36.,\n",
      "         -46.],\n",
      "       [  36.,  -18.,    9.,   36.,   36.,    9.,   58.,  -18.,  -46.,\n",
      "         -46.],\n",
      "       [  36.,  -18.,    9.,   58.,  -73.,   36.,  -18.,  -46.,  -46.,\n",
      "           9.],\n",
      "       [ -18.,   36.,  -18.,    9.,  -73.,   36.,    9.,  -46.,   58.,\n",
      "         -46.],\n",
      "       [ -18.,  -46.,  -18.,  -18.,   58.,    9.,   36.,  -46.,  -18.,\n",
      "         -18.],\n",
      "       [ -46.,  -46.,  -46.,   58.,   58.,  -73.,   58.,   36.,    9.,\n",
      "         -46.],\n",
      "       [ -73.,   36.,   58.,   58.,  -46.,    9.,  -46.,  -73.,   58.,\n",
      "         -46.],\n",
      "       [-110.,   58.,   58.,  -18.,    9.,   36.,  -18.,   36.,  -18.,\n",
      "           9.],\n",
      "       [ -18.,  -18.,  -18.,  -73.,   58.,  -46.,  -46.,  -18.,   36.,\n",
      "           9.],\n",
      "       [ -18.,  -18.,  -18.,  -46.,  -18., -110.,    9.,   36.,   58.,\n",
      "         -73.],\n",
      "       [  58.,    9.,  -73.,    9.,  -18.,  -73.,  -46.,  -18.,  -18.,\n",
      "         -18.],\n",
      "       [ -18.,   36.,  -46.,    9.,   36.,   36.,    9.,  -73.,    9.,\n",
      "         -46.],\n",
      "       [   9.,    9.,   36.,  -18.,  -73.,   36.,   36.,  -46.,  -46.,\n",
      "          36.],\n",
      "       [   9.,   58.,  -18.,  -73.,   36.,   36.,  -18.,  -18.,   36.,\n",
      "         -18.],\n",
      "       [ -46.,   58.,   36.,    9.,    9.,    9.,  -46.,   58.,  -46.,\n",
      "         -73.],\n",
      "       [  58.,  -18.,  -46.,  -18.,  -46.,   36.,  -46.,  -18.,    9.,\n",
      "         -46.],\n",
      "       [   9.,  -46.,   36.,   58.,   36.,  -73.,    9.,  -46.,  -18.,\n",
      "          58.],\n",
      "       [  58.,  -46.,   36.,  -18.,    9.,  -18.,  -46.,  -73.,    9.,\n",
      "         -18.],\n",
      "       [  36.,  -46.,   36.,   58.,    9.,    9.,    9.,  -46.,  -73.,\n",
      "          36.],\n",
      "       [  36.,   36.,    9.,  -18.,  -46., -110.,  -73.,   58.,   58.,\n",
      "          36.],\n",
      "       [   9.,    9.,  -46.,   36.,  -73.,  -46.,   58.,   58.,    9.,\n",
      "         -18.],\n",
      "       [ -18.,    9.,   58.,    9.,  -73.,  -73.,    9.,    9.,    9.,\n",
      "          36.],\n",
      "       [ -73.,  -18.,    9.,   36.,   36.,   36.,   36.,  -73.,   36.,\n",
      "          36.],\n",
      "       [ -46.,  -18.,    9.,  -73.,   36.,  -18.,    9.,    9.,  -46.,\n",
      "          36.],\n",
      "       [ -18.,  -18.,    9.,    9.,  -18.,   36.,   58.,   58.,    9.,\n",
      "        -110.],\n",
      "       [   9.,   58.,   36.,    9.,    9.,   36.,    9.,    9.,  -46.,\n",
      "         -46.],\n",
      "       [  58.,  -18.,   58.,   58.,    9.,  -18.,    9.,  -18.,    9.,\n",
      "         -73.],\n",
      "       [  36.,  -18.,   36.,  -46.,  -46.,  -46.,  -46.,  -46.,   58.,\n",
      "           9.],\n",
      "       [ -18.,  -18.,  -73.,   58.,   36.,  -73.,    9.,    9.,    9.,\n",
      "           9.],\n",
      "       [  36.,    9.,  -46.,  -18.,   36.,   58.,  -73.,  -46.,  -46.,\n",
      "          58.],\n",
      "       [ -73.,   58.,   58.,   36.,    9.,  -73.,  -73.,   36.,    9.,\n",
      "         -18.],\n",
      "       [  36.,  -18.,   58.,  -46.,  -46.,    9.,   36.,    9.,  -46.,\n",
      "         -18.],\n",
      "       [ -73.,  -18.,  -46.,  -18.,   36.,  107.,  -18.,  -46.,  -18.,\n",
      "          58.],\n",
      "       [  36.,  -18.,   36.,   36.,  -18., -110.,  -18.,   36.,  -46.,\n",
      "           9.],\n",
      "       [ -46.,   58.,  -18.,  -46.,   58., -110.,    9.,   36.,    9.,\n",
      "         -18.],\n",
      "       [ -46.,   58.,  -18.,  -18.,    9., -110.,  -46.,  -46.,  -18.,\n",
      "          58.],\n",
      "       [ -73.,    9.,   58.,  -73.,  -18.,   58.,   36.,  -46.,    9.,\n",
      "           9.],\n",
      "       [   9.,   36.,    9.,  -46.,  -73.,  -73.,  -18.,   36.,   36.,\n",
      "          58.],\n",
      "       [  36.,  -18.,    9.,   58.,  -73.,   36.,  -18.,    9.,   36.,\n",
      "         -18.],\n",
      "       [ -46.,  -46.,  -18.,    9.,  -18.,  107.,    9.,    9.,    9.,\n",
      "          36.],\n",
      "       [ -46.,  -46.,  -73.,  -46.,    9.,   58.,   58.,   58.,  -18.,\n",
      "         -18.],\n",
      "       [ -18.,    9.,  -46.,   58.,    9.,    9.,  -46.,  -46.,   36.,\n",
      "          36.],\n",
      "       [  36.,    9.,   36.,  -73.,  -18., -110.,  -73.,   58.,  -18.,\n",
      "          36.],\n",
      "       [  36.,   58.,    9.,    9.,  -46.,    9.,  -73.,  -18.,    9.,\n",
      "          36.],\n",
      "       [ -18.,   58.,   36.,   36.,  -46., -110.,  -73.,   36.,  -18.,\n",
      "         -46.],\n",
      "       [   9.,  -46.,    9.,    9.,   36.,    9.,  -46.,    9.,  -46.,\n",
      "         -73.],\n",
      "       [   9.,    9.,    9.,  -18.,    9.,   36.,   58.,   36.,  -46.,\n",
      "         -18.],\n",
      "       [   9.,  -18.,  -46.,  -18.,  -18.,   36.,   58.,    9.,  -46.,\n",
      "          36.],\n",
      "       [   9.,    9.,   58.,  -18.,   58., -110.,  -73.,  -46.,    9.,\n",
      "           9.],\n",
      "       [   9.,  -73.,    9.,    9.,  -73.,    9.,    9.,  -46.,  -18.,\n",
      "          36.],\n",
      "       [  36.,  -46.,    9.,  -18.,   58.,   58.,  -46.,   36.,    9.,\n",
      "         -73.],\n",
      "       [   9.,    9.,   58.,  -18.,    9.,  -18.,  -18.,   36.,   58.,\n",
      "           9.],\n",
      "       [   9.,   36.,    9.,    9.,   36., -110.,  -46.,   58.,  -18.,\n",
      "         -18.],\n",
      "       [  36.,    9.,  -73.,    9.,  -18.,  -18.,  -18.,   58.,  -18.,\n",
      "         -73.],\n",
      "       [  36.,    9.,  -46.,  -73.,   36.,  -18.,   58.,    9.,  -18.,\n",
      "         -18.]], dtype=float32)\n",
      " array([ 54., -82., -21.,  54.,  18.,  18.,  -6.,  18., -21.,  -6.],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# Read the quantized value and get the new weights then build the model\n",
    "\n",
    "def sample_create_codeval(model_name, codeX_name, codebooks_name):\n",
    "    model = loadModelJson(model_name)\n",
    "    codeXs = np.load(codeX_name)\n",
    "    codebooks = np.load(codebooks_name)\n",
    "    index = 0\n",
    "    for layer in model.layers:\n",
    "            print(layer)\n",
    "            existing_weight = layer.get_weights()\n",
    "            existing_weight_np = np.asarray(existing_weight)\n",
    "#             print(existing_weight_np)\n",
    "\n",
    "    #         if convolution layer we update both weight and bias\n",
    "            if existing_weight_np.shape == (2,):\n",
    "                new_w = []\n",
    "                for i in range (0,2):\n",
    "                    codebook = codebooks[index]\n",
    "                    codeX = codeXs[index]\n",
    "                    new_weight = create_codeVal(codeX, codebook, existing_weight_np[i].shape)\n",
    "                    index += 1\n",
    "                    new_w.append(new_weight)\n",
    "                new_weights = np.asarray(new_w)\n",
    "    #             all other layers which have parameters\n",
    "            elif existing_weight_np.shape != (0,) :\n",
    "                codebook = codebooks[index]\n",
    "                codeX = codeXs[index]\n",
    "                new_weights = create_codeVal(codeX, codebook, existing_weight_np.shape)\n",
    "                index += 1\n",
    "    #             for any layer with parameter we update the parametes\n",
    "            if existing_weight_np.shape != (0,) :\n",
    "                layer.set_weights(new_weights)\n",
    "\n",
    "            existing_weight = layer.get_weights()\n",
    "            existing_weight_np = np.asarray(existing_weight)\n",
    "            print(existing_weight_np)\n",
    "    return model\n",
    "            \n",
    "# we are calling the sample here which will give us the final model \n",
    "model = sample_create_codeval(\"model4\", \"codeX_file_dis.npy\", \"codebook_file_dis.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
